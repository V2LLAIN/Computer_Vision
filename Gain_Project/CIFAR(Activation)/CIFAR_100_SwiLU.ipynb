{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "435f2fe4-a4ef-4b66-a91f-6b6c598baa92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-22 01:27:02.530902: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-22 01:27:02.649561: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import wandb\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.losses import *\n",
    "from tensorflow.keras.metrics import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.activations import *\n",
    "\n",
    "from tensorflow.keras.regularizers import *\n",
    "\n",
    "from tensorflow.keras.callbacks import *\n",
    "from keras.preprocessing.image import *\n",
    "from tensorflow.keras.preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6970ba03-d344-4b3a-aca9-5b6fd275830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
    "\n",
    "# Normalize pixel values between 0 and 1\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Convert labels to one-hot encoded vectors\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=100)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fe35a65-5dc2-438b-b26b-c6a0a6bf9293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SwiLU 함수 정의 (alpha값 항상 1로 고정)\n",
    "def serlu(x, lamda = 1.0786, alpha= 1):\n",
    "    return tf.where(x>=0, x, alpha * x * tf.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2dac364-264e-4823-8695-e36d850d7ebe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 14, 14, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 14, 14, 32)        0         \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 12, 12, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 10, 10, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 5, 5, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 5, 5, 64)          0         \n",
      "                                                                 \n",
      " average_pooling2d_5 (Averag  (None, 2, 2, 64)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 100)               51300     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 248,452\n",
      "Trainable params: 248,452\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(32,32, 3))\n",
    "\n",
    "# Layer 1\n",
    "x = Conv2D(32, (3,3), activation=serlu, kernel_regularizer=l2(1e-6))(inputs)\n",
    "\n",
    "# Layer 2\n",
    "x = Conv2D(32, (3,3), activation=serlu, kernel_regularizer=l2(1e-6))(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "# Layer 3\n",
    "x = Conv2D(64, (3,3), activation=serlu, kernel_regularizer=l2(1e-6))(x)\n",
    "\n",
    "# Layer 4\n",
    "x = Conv2D(64, (3,3), activation=serlu, kernel_regularizer=l2(1e-6))(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "# Layer 5\n",
    "x = AveragePooling2D()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation=serlu, kernel_regularizer=l2(1e-6))(x)\n",
    "\n",
    "# Layer 6\n",
    "outputs = Dense(100, activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9897576-4328-4349-90b8-2ac97f68f424",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 옵티마이저 및 학습률 스케줄러 정의\n",
    "# 옵티마이저 정의\n",
    "learning_rate = 1e-3\n",
    "\n",
    "def learning_rate_schedule(epoch):\n",
    "    new_learning_rate = learning_rate\n",
    "\n",
    "    if epoch <= 50:\n",
    "        pass\n",
    "    elif epoch > 50 and epoch <= 100:\n",
    "        new_learning_rate = learning_rate * 0.1\n",
    "    else:\n",
    "        new_learning_rate = learning_rate * 0.01\n",
    "        \n",
    "    print('Learning rate:', new_learning_rate)\n",
    "    \n",
    "    return new_learning_rate\n",
    "\n",
    "\n",
    "opt = tf.keras.optimizers.RMSprop(learning_rate=learning_rate )\n",
    "\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b0c4da2-fa25-4117-a366-a44db57afcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(horizontal_flip=True,\n",
    "                             vertical_flip= True\n",
    "                             )\n",
    "\n",
    "# 이미지 데이터의 분포를 조정\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "492f7e1e-df54-4686-aaca-ba346e556926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:k7ykgaad) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5185b3492240ea85bb1acfb7e6d5e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LeNet-swilu</strong> at: <a href='https://wandb.ai/hcim/CIFAR100/runs/k7ykgaad' target=\"_blank\">https://wandb.ai/hcim/CIFAR100/runs/k7ykgaad</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230422_020806-k7ykgaad/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:k7ykgaad). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8233ce7bf1845a5a3a188692f3e1391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668086850161974, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/jupyter/IHC/gain_proj/wandb/run-20230422_020815-zl73pz92</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hcim/CIFAR100/runs/zl73pz92' target=\"_blank\">LeNet-swilu</a></strong> to <a href='https://wandb.ai/hcim/CIFAR100' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hcim/CIFAR100' target=\"_blank\">https://wandb.ai/hcim/CIFAR100</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hcim/CIFAR100/runs/zl73pz92' target=\"_blank\">https://wandb.ai/hcim/CIFAR100/runs/zl73pz92</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "\n",
    "wandb.init(project=\"CIFAR100\", entity=\"hcim\", name='LeNet-swilu')\n",
    "\n",
    "wandbCallback=wandb.keras.WandbCallback(monitor=\"val_accuracy\", mode=\"max\", \n",
    "                                        log_weights=True, log_gradients=True, \n",
    "                                        training_data=datagen.flow(x_train, y_train, batch_size=128))\n",
    "\n",
    "\n",
    "callbacks = [wandbCallback, LearningRateScheduler(learning_rate_schedule)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e995314-6225-4052-95d8-03e5235ea600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001\n",
      "Epoch 1/200\n",
      "  1/391 [..............................] - ETA: 5:19 - loss: 4.6096 - accuracy: 0.0156"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-22 02:08:23.743985: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape ingradient_tape/model_11/conv2d_23/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388/391 [============================>.] - ETA: 0s - loss: 3.8789 - accuracy: 0.1089"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-22 02:08:29.224912: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape ingradient_tape/model_12/model_11/conv2d_23/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/wandb/run-20230422_020815-zl73pz92/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 14s 33ms/step - loss: 3.8767 - accuracy: 0.1092 - val_loss: 3.4766 - val_accuracy: 0.1733 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 2/200\n",
      "389/391 [============================>.] - ETA: 0s - loss: 3.2799 - accuracy: 0.2126"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/wandb/run-20230422_020815-zl73pz92/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 30ms/step - loss: 3.2794 - accuracy: 0.2126 - val_loss: 3.0762 - val_accuracy: 0.2461 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 3/200\n",
      "388/391 [============================>.] - ETA: 0s - loss: 2.9496 - accuracy: 0.2695"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/wandb/run-20230422_020815-zl73pz92/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 30ms/step - loss: 2.9488 - accuracy: 0.2696 - val_loss: 2.8290 - val_accuracy: 0.2913 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 2.7355 - accuracy: 0.3121"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/wandb/run-20230422_020815-zl73pz92/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 30ms/step - loss: 2.7355 - accuracy: 0.3121 - val_loss: 2.6736 - val_accuracy: 0.3269 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 5/200\n",
      "390/391 [============================>.] - ETA: 0s - loss: 2.5852 - accuracy: 0.3418"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/wandb/run-20230422_020815-zl73pz92/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 30ms/step - loss: 2.5855 - accuracy: 0.3417 - val_loss: 2.5771 - val_accuracy: 0.3403 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 6/200\n",
      "387/391 [============================>.] - ETA: 0s - loss: 2.4545 - accuracy: 0.3678"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/wandb/run-20230422_020815-zl73pz92/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 30ms/step - loss: 2.4564 - accuracy: 0.3676 - val_loss: 2.5123 - val_accuracy: 0.3582 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 7/200\n",
      "386/391 [============================>.] - ETA: 0s - loss: 2.3603 - accuracy: 0.3869"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/wandb/run-20230422_020815-zl73pz92/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 30ms/step - loss: 2.3609 - accuracy: 0.3869 - val_loss: 2.3962 - val_accuracy: 0.3873 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 8/200\n",
      "389/391 [============================>.] - ETA: 0s - loss: 2.2752 - accuracy: 0.4074"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/wandb/run-20230422_020815-zl73pz92/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 31ms/step - loss: 2.2743 - accuracy: 0.4076 - val_loss: 2.3494 - val_accuracy: 0.3905 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 9/200\n",
      "387/391 [============================>.] - ETA: 0s - loss: 2.2026 - accuracy: 0.4244"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/wandb/run-20230422_020815-zl73pz92/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 30ms/step - loss: 2.2033 - accuracy: 0.4241 - val_loss: 2.2854 - val_accuracy: 0.4022 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 10/200\n",
      "387/391 [============================>.] - ETA: 0s - loss: 2.1403 - accuracy: 0.4360"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/wandb/run-20230422_020815-zl73pz92/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 31ms/step - loss: 2.1393 - accuracy: 0.4362 - val_loss: 2.2616 - val_accuracy: 0.4139 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 11/200\n",
      "388/391 [============================>.] - ETA: 0s - loss: 2.0842 - accuracy: 0.4460"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/wandb/run-20230422_020815-zl73pz92/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 30ms/step - loss: 2.0847 - accuracy: 0.4460 - val_loss: 2.2385 - val_accuracy: 0.4179 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 10s 27ms/step - loss: 2.0381 - accuracy: 0.4581 - val_loss: 2.2793 - val_accuracy: 0.4145 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 13/200\n",
      "386/391 [============================>.] - ETA: 0s - loss: 1.9878 - accuracy: 0.4684"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/wandb/run-20230422_020815-zl73pz92/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 30ms/step - loss: 1.9890 - accuracy: 0.4683 - val_loss: 2.2273 - val_accuracy: 0.4280 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 1.9485 - accuracy: 0.4771 - val_loss: 2.2449 - val_accuracy: 0.4222 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 15/200\n",
      "386/391 [============================>.] - ETA: 0s - loss: 1.9186 - accuracy: 0.4840"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/wandb/run-20230422_020815-zl73pz92/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 30ms/step - loss: 1.9172 - accuracy: 0.4844 - val_loss: 2.2006 - val_accuracy: 0.4326 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 16/200\n",
      "388/391 [============================>.] - ETA: 0s - loss: 1.8825 - accuracy: 0.4928"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/wandb/run-20230422_020815-zl73pz92/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 30ms/step - loss: 1.8825 - accuracy: 0.4925 - val_loss: 2.1962 - val_accuracy: 0.4338 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 17/200\n",
      "388/391 [============================>.] - ETA: 0s - loss: 1.8485 - accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/wandb/run-20230422_020815-zl73pz92/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 30ms/step - loss: 1.8493 - accuracy: 0.4998 - val_loss: 2.1670 - val_accuracy: 0.4465 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 1.8127 - accuracy: 0.5093 - val_loss: 2.1733 - val_accuracy: 0.4426 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 1.7900 - accuracy: 0.5158 - val_loss: 2.1821 - val_accuracy: 0.4415 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 1.7596 - accuracy: 0.5211 - val_loss: 2.1499 - val_accuracy: 0.4451 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 21/200\n",
      "388/391 [============================>.] - ETA: 0s - loss: 1.7331 - accuracy: 0.5264"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/wandb/run-20230422_020815-zl73pz92/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 13s 33ms/step - loss: 1.7329 - accuracy: 0.5263 - val_loss: 2.1701 - val_accuracy: 0.4474 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.7122 - accuracy: 0.5313"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/wandb/run-20230422_020815-zl73pz92/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 31ms/step - loss: 1.7122 - accuracy: 0.5313 - val_loss: 2.1555 - val_accuracy: 0.4500 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.6855 - accuracy: 0.5373"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/wandb/run-20230422_020815-zl73pz92/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 31ms/step - loss: 1.6855 - accuracy: 0.5373 - val_loss: 2.1593 - val_accuracy: 0.4509 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 24/200\n",
      "391/391 [==============================] - 10s 27ms/step - loss: 1.6651 - accuracy: 0.5440 - val_loss: 2.1716 - val_accuracy: 0.4489 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.6482 - accuracy: 0.5444"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/wandb/run-20230422_020815-zl73pz92/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 30ms/step - loss: 1.6482 - accuracy: 0.5444 - val_loss: 2.1531 - val_accuracy: 0.4583 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 26/200\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 1.6320 - accuracy: 0.5524 - val_loss: 2.1773 - val_accuracy: 0.4482 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 27/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1.6197 - accuracy: 0.5532 - val_loss: 2.1569 - val_accuracy: 0.4566 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 10s 27ms/step - loss: 1.6016 - accuracy: 0.5582 - val_loss: 2.1498 - val_accuracy: 0.4560 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 29/200\n",
      "390/391 [============================>.] - ETA: 0s - loss: 1.5717 - accuracy: 0.5604"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/wandb/run-20230422_020815-zl73pz92/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 30ms/step - loss: 1.5713 - accuracy: 0.5605 - val_loss: 2.1662 - val_accuracy: 0.4622 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 10s 27ms/step - loss: 1.5666 - accuracy: 0.5642 - val_loss: 2.1543 - val_accuracy: 0.4539 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 1.5422 - accuracy: 0.5706 - val_loss: 2.1832 - val_accuracy: 0.4596 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 32/200\n",
      "386/391 [============================>.] - ETA: 0s - loss: 1.5318 - accuracy: 0.5747"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/wandb/run-20230422_020815-zl73pz92/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 31ms/step - loss: 1.5329 - accuracy: 0.5743 - val_loss: 2.1664 - val_accuracy: 0.4645 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1.5256 - accuracy: 0.5772 - val_loss: 2.2122 - val_accuracy: 0.4592 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 34/200\n",
      "388/391 [============================>.] - ETA: 0s - loss: 1.5073 - accuracy: 0.5802"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/wandb/run-20230422_020815-zl73pz92/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 30ms/step - loss: 1.5080 - accuracy: 0.5804 - val_loss: 2.1615 - val_accuracy: 0.4655 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 10s 27ms/step - loss: 1.4985 - accuracy: 0.5814 - val_loss: 2.1614 - val_accuracy: 0.4608 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 1.4848 - accuracy: 0.5863 - val_loss: 2.2631 - val_accuracy: 0.4521 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 1.4742 - accuracy: 0.5874 - val_loss: 2.1682 - val_accuracy: 0.4597 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.4599 - accuracy: 0.5882"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/wandb/run-20230422_020815-zl73pz92/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 31ms/step - loss: 1.4599 - accuracy: 0.5882 - val_loss: 2.1684 - val_accuracy: 0.4666 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1.4470 - accuracy: 0.5940 - val_loss: 2.2018 - val_accuracy: 0.4622 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 10s 27ms/step - loss: 1.4442 - accuracy: 0.5932 - val_loss: 2.2158 - val_accuracy: 0.4640 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 1.4336 - accuracy: 0.5980 - val_loss: 2.2143 - val_accuracy: 0.4605 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 1.4127 - accuracy: 0.6021 - val_loss: 2.1980 - val_accuracy: 0.4625 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 10s 27ms/step - loss: 1.4109 - accuracy: 0.6023 - val_loss: 2.2103 - val_accuracy: 0.4633 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 10s 27ms/step - loss: 1.4006 - accuracy: 0.6030 - val_loss: 2.2349 - val_accuracy: 0.4613 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1.3883 - accuracy: 0.6071 - val_loss: 2.2398 - val_accuracy: 0.4614 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 10s 27ms/step - loss: 1.3876 - accuracy: 0.6073 - val_loss: 2.2187 - val_accuracy: 0.4662 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 47/200\n",
      "389/391 [============================>.] - ETA: 0s - loss: 1.3798 - accuracy: 0.6107"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/wandb/run-20230422_020815-zl73pz92/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 31ms/step - loss: 1.3802 - accuracy: 0.6106 - val_loss: 2.2355 - val_accuracy: 0.4671 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 48/200\n",
      "386/391 [============================>.] - ETA: 0s - loss: 1.3605 - accuracy: 0.6141"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/wandb/run-20230422_020815-zl73pz92/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 30ms/step - loss: 1.3615 - accuracy: 0.6137 - val_loss: 2.2314 - val_accuracy: 0.4702 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 1.3590 - accuracy: 0.6145 - val_loss: 2.2917 - val_accuracy: 0.4599 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 1.3562 - accuracy: 0.6160 - val_loss: 2.2350 - val_accuracy: 0.4667 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 51/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1.3402 - accuracy: 0.6185 - val_loss: 2.2434 - val_accuracy: 0.4670 - lr: 0.0010\n",
      "Learning rate: 0.0001\n",
      "Epoch 52/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.1631 - accuracy: 0.6683"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/wandb/run-20230422_020815-zl73pz92/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 30ms/step - loss: 1.1631 - accuracy: 0.6683 - val_loss: 2.1296 - val_accuracy: 0.4877 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 53/200\n",
      "386/391 [============================>.] - ETA: 0s - loss: 1.1168 - accuracy: 0.6783"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/wandb/run-20230422_020815-zl73pz92/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 30ms/step - loss: 1.1174 - accuracy: 0.6784 - val_loss: 2.1245 - val_accuracy: 0.4889 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 54/200\n",
      "386/391 [============================>.] - ETA: 0s - loss: 1.1028 - accuracy: 0.6825"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/wandb/run-20230422_020815-zl73pz92/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 13s 32ms/step - loss: 1.1028 - accuracy: 0.6824 - val_loss: 2.1204 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 55/200\n",
      "388/391 [============================>.] - ETA: 0s - loss: 1.1024 - accuracy: 0.6847"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/wandb/run-20230422_020815-zl73pz92/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 31ms/step - loss: 1.1029 - accuracy: 0.6844 - val_loss: 2.1231 - val_accuracy: 0.4902 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 10s 27ms/step - loss: 1.0888 - accuracy: 0.6871 - val_loss: 2.1264 - val_accuracy: 0.4902 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 57/200\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 1.0892 - accuracy: 0.6888 - val_loss: 2.1299 - val_accuracy: 0.4900 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 58/200\n",
      "390/391 [============================>.] - ETA: 0s - loss: 1.0721 - accuracy: 0.6942"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/wandb/run-20230422_020815-zl73pz92/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 12s 30ms/step - loss: 1.0718 - accuracy: 0.6944 - val_loss: 2.1244 - val_accuracy: 0.4946 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.0710 - accuracy: 0.6929 - val_loss: 2.1341 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.0697 - accuracy: 0.6922 - val_loss: 2.1378 - val_accuracy: 0.4898 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.0564 - accuracy: 0.6982 - val_loss: 2.1354 - val_accuracy: 0.4925 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1.0573 - accuracy: 0.6952 - val_loss: 2.1411 - val_accuracy: 0.4923 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.0546 - accuracy: 0.6976 - val_loss: 2.1346 - val_accuracy: 0.4942 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.0533 - accuracy: 0.6972 - val_loss: 2.1407 - val_accuracy: 0.4931 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.0421 - accuracy: 0.7010 - val_loss: 2.1411 - val_accuracy: 0.4903 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.0471 - accuracy: 0.6964 - val_loss: 2.1376 - val_accuracy: 0.4937 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.0396 - accuracy: 0.7003 - val_loss: 2.1465 - val_accuracy: 0.4929 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1.0468 - accuracy: 0.6970 - val_loss: 2.1480 - val_accuracy: 0.4934 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1.0377 - accuracy: 0.7008 - val_loss: 2.1539 - val_accuracy: 0.4926 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.0323 - accuracy: 0.7046 - val_loss: 2.1550 - val_accuracy: 0.4923 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.0398 - accuracy: 0.7007 - val_loss: 2.1539 - val_accuracy: 0.4915 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.0249 - accuracy: 0.7042 - val_loss: 2.1562 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.0280 - accuracy: 0.7038 - val_loss: 2.1523 - val_accuracy: 0.4930 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1.0320 - accuracy: 0.7016 - val_loss: 2.1613 - val_accuracy: 0.4931 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1.0221 - accuracy: 0.7050 - val_loss: 2.1566 - val_accuracy: 0.4928 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.0208 - accuracy: 0.7047 - val_loss: 2.1636 - val_accuracy: 0.4917 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 77/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.0213 - accuracy: 0.7047 - val_loss: 2.1628 - val_accuracy: 0.4888 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.0147 - accuracy: 0.7085 - val_loss: 2.1698 - val_accuracy: 0.4909 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.0124 - accuracy: 0.7063 - val_loss: 2.1666 - val_accuracy: 0.4912 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.0108 - accuracy: 0.7079 - val_loss: 2.1690 - val_accuracy: 0.4928 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1.0133 - accuracy: 0.7066 - val_loss: 2.1704 - val_accuracy: 0.4926 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.0111 - accuracy: 0.7055 - val_loss: 2.1745 - val_accuracy: 0.4921 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.0094 - accuracy: 0.7082 - val_loss: 2.1785 - val_accuracy: 0.4929 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.0094 - accuracy: 0.7081 - val_loss: 2.1695 - val_accuracy: 0.4893 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.0060 - accuracy: 0.7101 - val_loss: 2.1797 - val_accuracy: 0.4939 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.0008 - accuracy: 0.7110 - val_loss: 2.1742 - val_accuracy: 0.4915 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 1.0037 - accuracy: 0.7081 - val_loss: 2.1795 - val_accuracy: 0.4910 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.0075 - accuracy: 0.7062 - val_loss: 2.1767 - val_accuracy: 0.4932 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 1.0020 - accuracy: 0.7111 - val_loss: 2.1799 - val_accuracy: 0.4937 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9953 - accuracy: 0.7103 - val_loss: 2.1842 - val_accuracy: 0.4885 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9881 - accuracy: 0.7136 - val_loss: 2.1834 - val_accuracy: 0.4920 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 0.9918 - accuracy: 0.7125 - val_loss: 2.1825 - val_accuracy: 0.4919 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 0.9831 - accuracy: 0.7146 - val_loss: 2.1868 - val_accuracy: 0.4914 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9901 - accuracy: 0.7147 - val_loss: 2.1959 - val_accuracy: 0.4941 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9938 - accuracy: 0.7121 - val_loss: 2.1898 - val_accuracy: 0.4906 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9875 - accuracy: 0.7113 - val_loss: 2.1926 - val_accuracy: 0.4916 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9845 - accuracy: 0.7146 - val_loss: 2.1968 - val_accuracy: 0.4926 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9835 - accuracy: 0.7132 - val_loss: 2.2027 - val_accuracy: 0.4921 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 0.9798 - accuracy: 0.7138 - val_loss: 2.2026 - val_accuracy: 0.4882 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9799 - accuracy: 0.7142 - val_loss: 2.2039 - val_accuracy: 0.4896 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9789 - accuracy: 0.7165 - val_loss: 2.2036 - val_accuracy: 0.4901 - lr: 1.0000e-04\n",
      "Learning rate: 1e-05\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9613 - accuracy: 0.7212 - val_loss: 2.1960 - val_accuracy: 0.4910 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9607 - accuracy: 0.7201 - val_loss: 2.1961 - val_accuracy: 0.4915 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9561 - accuracy: 0.7234 - val_loss: 2.1947 - val_accuracy: 0.4909 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.9625 - accuracy: 0.7201 - val_loss: 2.1956 - val_accuracy: 0.4909 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9557 - accuracy: 0.7227 - val_loss: 2.1963 - val_accuracy: 0.4910 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9617 - accuracy: 0.7216 - val_loss: 2.1965 - val_accuracy: 0.4913 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9461 - accuracy: 0.7234 - val_loss: 2.1971 - val_accuracy: 0.4921 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9511 - accuracy: 0.7238 - val_loss: 2.1957 - val_accuracy: 0.4926 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9571 - accuracy: 0.7215 - val_loss: 2.1953 - val_accuracy: 0.4918 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.9545 - accuracy: 0.7223 - val_loss: 2.1963 - val_accuracy: 0.4923 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9510 - accuracy: 0.7240 - val_loss: 2.1979 - val_accuracy: 0.4916 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9569 - accuracy: 0.7217 - val_loss: 2.1960 - val_accuracy: 0.4916 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9565 - accuracy: 0.7234 - val_loss: 2.1948 - val_accuracy: 0.4910 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9503 - accuracy: 0.7253 - val_loss: 2.1955 - val_accuracy: 0.4919 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9517 - accuracy: 0.7247 - val_loss: 2.1964 - val_accuracy: 0.4916 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.9498 - accuracy: 0.7248 - val_loss: 2.1970 - val_accuracy: 0.4918 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9536 - accuracy: 0.7220 - val_loss: 2.1960 - val_accuracy: 0.4911 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9525 - accuracy: 0.7222 - val_loss: 2.1961 - val_accuracy: 0.4909 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9529 - accuracy: 0.7238 - val_loss: 2.1975 - val_accuracy: 0.4908 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9533 - accuracy: 0.7230 - val_loss: 2.1970 - val_accuracy: 0.4925 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9535 - accuracy: 0.7217 - val_loss: 2.1965 - val_accuracy: 0.4913 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.9568 - accuracy: 0.7215 - val_loss: 2.1951 - val_accuracy: 0.4918 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9589 - accuracy: 0.7221 - val_loss: 2.1963 - val_accuracy: 0.4916 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9481 - accuracy: 0.7238 - val_loss: 2.1976 - val_accuracy: 0.4917 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9547 - accuracy: 0.7215 - val_loss: 2.1977 - val_accuracy: 0.4923 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9489 - accuracy: 0.7232 - val_loss: 2.1984 - val_accuracy: 0.4909 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9469 - accuracy: 0.7268 - val_loss: 2.1975 - val_accuracy: 0.4904 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 0.9486 - accuracy: 0.7237 - val_loss: 2.1960 - val_accuracy: 0.4913 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9533 - accuracy: 0.7223 - val_loss: 2.1975 - val_accuracy: 0.4911 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9517 - accuracy: 0.7224 - val_loss: 2.1988 - val_accuracy: 0.4932 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9495 - accuracy: 0.7250 - val_loss: 2.1971 - val_accuracy: 0.4920 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9536 - accuracy: 0.7222 - val_loss: 2.1970 - val_accuracy: 0.4921 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9460 - accuracy: 0.7260 - val_loss: 2.1987 - val_accuracy: 0.4923 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 0.9533 - accuracy: 0.7222 - val_loss: 2.1978 - val_accuracy: 0.4898 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9472 - accuracy: 0.7262 - val_loss: 2.1984 - val_accuracy: 0.4922 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9503 - accuracy: 0.7240 - val_loss: 2.1989 - val_accuracy: 0.4925 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9532 - accuracy: 0.7226 - val_loss: 2.1985 - val_accuracy: 0.4917 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9495 - accuracy: 0.7229 - val_loss: 2.2000 - val_accuracy: 0.4926 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9490 - accuracy: 0.7236 - val_loss: 2.1995 - val_accuracy: 0.4922 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 0.9558 - accuracy: 0.7228 - val_loss: 2.1993 - val_accuracy: 0.4918 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 0.9562 - accuracy: 0.7200 - val_loss: 2.1978 - val_accuracy: 0.4913 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9457 - accuracy: 0.7244 - val_loss: 2.2004 - val_accuracy: 0.4920 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9488 - accuracy: 0.7238 - val_loss: 2.1991 - val_accuracy: 0.4915 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9483 - accuracy: 0.7252 - val_loss: 2.1993 - val_accuracy: 0.4912 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9487 - accuracy: 0.7238 - val_loss: 2.1997 - val_accuracy: 0.4904 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 0.9486 - accuracy: 0.7238 - val_loss: 2.2008 - val_accuracy: 0.4900 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 0.9473 - accuracy: 0.7224 - val_loss: 2.2001 - val_accuracy: 0.4914 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9505 - accuracy: 0.7246 - val_loss: 2.1997 - val_accuracy: 0.4903 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9402 - accuracy: 0.7258 - val_loss: 2.2006 - val_accuracy: 0.4908 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9426 - accuracy: 0.7254 - val_loss: 2.2003 - val_accuracy: 0.4906 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9436 - accuracy: 0.7254 - val_loss: 2.2008 - val_accuracy: 0.4907 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 153/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 0.9475 - accuracy: 0.7230 - val_loss: 2.2012 - val_accuracy: 0.4907 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 0.9503 - accuracy: 0.7242 - val_loss: 2.2022 - val_accuracy: 0.4916 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9446 - accuracy: 0.7249 - val_loss: 2.2016 - val_accuracy: 0.4916 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9459 - accuracy: 0.7247 - val_loss: 2.2006 - val_accuracy: 0.4917 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9451 - accuracy: 0.7250 - val_loss: 2.2019 - val_accuracy: 0.4913 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9487 - accuracy: 0.7252 - val_loss: 2.2010 - val_accuracy: 0.4913 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9438 - accuracy: 0.7273 - val_loss: 2.2003 - val_accuracy: 0.4912 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 0.9418 - accuracy: 0.7276 - val_loss: 2.2025 - val_accuracy: 0.4909 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9478 - accuracy: 0.7236 - val_loss: 2.2018 - val_accuracy: 0.4919 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9391 - accuracy: 0.7283 - val_loss: 2.2015 - val_accuracy: 0.4913 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9431 - accuracy: 0.7249 - val_loss: 2.2035 - val_accuracy: 0.4905 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9448 - accuracy: 0.7265 - val_loss: 2.2028 - val_accuracy: 0.4910 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9469 - accuracy: 0.7237 - val_loss: 2.2034 - val_accuracy: 0.4920 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.9432 - accuracy: 0.7253 - val_loss: 2.2038 - val_accuracy: 0.4918 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9467 - accuracy: 0.7264 - val_loss: 2.2024 - val_accuracy: 0.4915 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9409 - accuracy: 0.7259 - val_loss: 2.2029 - val_accuracy: 0.4900 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9437 - accuracy: 0.7254 - val_loss: 2.2020 - val_accuracy: 0.4905 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9412 - accuracy: 0.7253 - val_loss: 2.2024 - val_accuracy: 0.4906 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9462 - accuracy: 0.7235 - val_loss: 2.2033 - val_accuracy: 0.4908 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 0.9436 - accuracy: 0.7262 - val_loss: 2.2039 - val_accuracy: 0.4912 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9358 - accuracy: 0.7284 - val_loss: 2.2031 - val_accuracy: 0.4909 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9414 - accuracy: 0.7262 - val_loss: 2.2039 - val_accuracy: 0.4904 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9378 - accuracy: 0.7256 - val_loss: 2.2043 - val_accuracy: 0.4915 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9532 - accuracy: 0.7221 - val_loss: 2.2019 - val_accuracy: 0.4926 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9455 - accuracy: 0.7247 - val_loss: 2.2048 - val_accuracy: 0.4902 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.9339 - accuracy: 0.7284 - val_loss: 2.2037 - val_accuracy: 0.4909 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9402 - accuracy: 0.7263 - val_loss: 2.2042 - val_accuracy: 0.4907 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9400 - accuracy: 0.7259 - val_loss: 2.2055 - val_accuracy: 0.4906 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9417 - accuracy: 0.7261 - val_loss: 2.2045 - val_accuracy: 0.4901 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9380 - accuracy: 0.7267 - val_loss: 2.2052 - val_accuracy: 0.4917 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9363 - accuracy: 0.7278 - val_loss: 2.2062 - val_accuracy: 0.4905 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.9393 - accuracy: 0.7257 - val_loss: 2.2046 - val_accuracy: 0.4912 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9423 - accuracy: 0.7236 - val_loss: 2.2037 - val_accuracy: 0.4899 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9380 - accuracy: 0.7272 - val_loss: 2.2074 - val_accuracy: 0.4906 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9420 - accuracy: 0.7252 - val_loss: 2.2061 - val_accuracy: 0.4904 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9425 - accuracy: 0.7262 - val_loss: 2.2044 - val_accuracy: 0.4903 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 189/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9376 - accuracy: 0.7276 - val_loss: 2.2049 - val_accuracy: 0.4906 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 190/200\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.9377 - accuracy: 0.7278 - val_loss: 2.2068 - val_accuracy: 0.4910 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9395 - accuracy: 0.7270 - val_loss: 2.2070 - val_accuracy: 0.4914 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9383 - accuracy: 0.7267 - val_loss: 2.2080 - val_accuracy: 0.4908 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9406 - accuracy: 0.7247 - val_loss: 2.2063 - val_accuracy: 0.4916 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9430 - accuracy: 0.7257 - val_loss: 2.2057 - val_accuracy: 0.4915 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9322 - accuracy: 0.7277 - val_loss: 2.2088 - val_accuracy: 0.4914 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 11s 28ms/step - loss: 0.9400 - accuracy: 0.7256 - val_loss: 2.2065 - val_accuracy: 0.4906 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9410 - accuracy: 0.7247 - val_loss: 2.2062 - val_accuracy: 0.4898 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9396 - accuracy: 0.7246 - val_loss: 2.2086 - val_accuracy: 0.4913 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9404 - accuracy: 0.7246 - val_loss: 2.2094 - val_accuracy: 0.4907 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 11s 27ms/step - loss: 0.9375 - accuracy: 0.7277 - val_loss: 2.2089 - val_accuracy: 0.4905 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4165d02430>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(datagen.flow(x_train, y_train, batch_size=128),\n",
    "          validation_data=(x_test, y_test),\n",
    "          epochs=200, workers=4,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b680e-40d0-4d11-9d99-3e44c26ad381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7a27fb-7c93-4b43-9bf2-7fc2bc6a5071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38a00d3-8096-409b-90a5-ce799e67d313",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
