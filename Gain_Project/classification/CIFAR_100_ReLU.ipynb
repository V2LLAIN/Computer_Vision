{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "435f2fe4-a4ef-4b66-a91f-6b6c598baa92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 11:57:49.095766: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-21 11:57:49.216498: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import wandb\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.losses import *\n",
    "from tensorflow.keras.metrics import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.activations import *\n",
    "\n",
    "from tensorflow.keras.regularizers import *\n",
    "\n",
    "from tensorflow.keras.callbacks import *\n",
    "from keras.preprocessing.image import *\n",
    "from tensorflow.keras.preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6970ba03-d344-4b3a-aca9-5b6fd275830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
    "\n",
    "# Normalize pixel values between 0 and 1\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Convert labels to one-hot encoded vectors\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=100)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7b29893b-365b-49f7-9872-60c8052be25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def building_block(X, filter_size, filters, stride=1):\n",
    "\n",
    "    # Save the input value for shortcut\n",
    "    X_shortcut = X\n",
    "\n",
    "    # Reshape shortcut for later adding if dimensions change\n",
    "    if stride > 1:\n",
    "\n",
    "        X_shortcut = Conv2D(filters, (1, 1), strides=stride, padding='same')(X_shortcut)\n",
    "        X_shortcut = BatchNormalization(axis=3)(X_shortcut)\n",
    "\n",
    "    # First layer of the block\n",
    "    X = Conv2D(filters, kernel_size = filter_size, strides=stride, padding='same')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second layer of the block\n",
    "    X = Conv2D(filters, kernel_size = filter_size, strides=(1, 1), padding='same')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = add([X, X_shortcut])  # Add shortcut value to main path\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X\n",
    "\n",
    "def ResNet32(input_shape, classes, name):\n",
    "\n",
    "    # Define the input\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Stage 1\n",
    "    X = Conv2D(filters=16, kernel_size=3, strides=(1, 1), padding='same')(X_input)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = building_block(X, filter_size=3, filters=16, stride=1)\n",
    "    X = building_block(X, filter_size=3, filters=16, stride=1)\n",
    "    X = building_block(X, filter_size=3, filters=16, stride=1)\n",
    "    X = building_block(X, filter_size=3, filters=16, stride=1)\n",
    "    X = building_block(X, filter_size=3, filters=16, stride=1)\n",
    "\n",
    "    # Stage 3\n",
    "    X = building_block(X, filter_size=3, filters=32, stride=2)  # dimensions change (stride=2)\n",
    "    X = building_block(X, filter_size=3, filters=32, stride=1)\n",
    "    X = building_block(X, filter_size=3, filters=32, stride=1)\n",
    "    X = building_block(X, filter_size=3, filters=32, stride=1)\n",
    "    X = building_block(X, filter_size=3, filters=32, stride=1)\n",
    "\n",
    "    # Stage 4\n",
    "    X = building_block(X, filter_size=3, filters=64, stride=2)  # dimensions change (stride=2)\n",
    "    X = building_block(X, filter_size=3, filters=64, stride=1)\n",
    "    X = building_block(X, filter_size=3, filters=64, stride=1)\n",
    "    X = building_block(X, filter_size=3, filters=64, stride=1)\n",
    "    X = building_block(X, filter_size=3, filters=64, stride=1)\n",
    "\n",
    "    # Average pooling and output layer\n",
    "    X = GlobalAveragePooling2D()(X)\n",
    "    X = Dense(classes, activation='softmax')(X)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs=X_input, outputs=X, name=name)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c746be2a-3733-445f-828c-bfc236bbaef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = list(x_train.shape[1:])\n",
    "classes = y_train.shape[1]\n",
    "model = ResNet32(input_shape=input_shape, classes=classes, name='ResNet32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c9897576-4328-4349-90b8-2ac97f68f424",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 옵티마이저 및 학습률 스케줄러 정의\n",
    "# 옵티마이저 정의\n",
    "learning_rate = 1e-3\n",
    "\n",
    "def learning_rate_schedule(epoch):\n",
    "    new_learning_rate = learning_rate\n",
    "\n",
    "    if epoch <= 50:\n",
    "        pass\n",
    "    elif epoch > 50 and epoch <= 100:\n",
    "        new_learning_rate = learning_rate * 0.1\n",
    "    else:\n",
    "        new_learning_rate = learning_rate * 0.01\n",
    "        \n",
    "    print('Learning rate:', new_learning_rate)\n",
    "    \n",
    "    return new_learning_rate\n",
    "\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5b0c4da2-fa25-4117-a366-a44db57afcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(horizontal_flip=True,\n",
    "                             vertical_flip= True\n",
    "                             )\n",
    "\n",
    "# 이미지 데이터의 분포를 조정\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "492f7e1e-df54-4686-aaca-ba346e556926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:m5chdqtj) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a9a429f0cb4c95821cf306e40731ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.312134…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ResNet-relu</strong> at: <a href='https://wandb.ai/hcim/CIFAR100/runs/m5chdqtj' target=\"_blank\">https://wandb.ai/hcim/CIFAR100/runs/m5chdqtj</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230522_020228-m5chdqtj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:m5chdqtj). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b573c12de64dc582bc8d1ec90d343c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666799043305218, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/jupyter/IHC/gain_proj/ResNet50_CIFAR/CIFAR_100/wandb/run-20230522_021825-ptsv149v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hcim/CIFAR100/runs/ptsv149v' target=\"_blank\">ResNet-relu</a></strong> to <a href='https://wandb.ai/hcim/CIFAR100' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hcim/CIFAR100' target=\"_blank\">https://wandb.ai/hcim/CIFAR100</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hcim/CIFAR100/runs/ptsv149v' target=\"_blank\">https://wandb.ai/hcim/CIFAR100/runs/ptsv149v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "\n",
    "wandb.init(project=\"CIFAR100\", entity=\"hcim\", name='ResNet-relu')\n",
    "\n",
    "wandbCallback=wandb.keras.WandbCallback(monitor=\"val_accuracy\", mode=\"max\", \n",
    "                                        log_weights=True, log_gradients=True, \n",
    "                                        training_data=datagen.flow(x_train, y_train, batch_size=128))\n",
    "\n",
    "\n",
    "callbacks = [wandbCallback, LearningRateScheduler(learning_rate_schedule)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9e995314-6225-4052-95d8-03e5235ea600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001\n",
      "Epoch 1/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 4.0045 - accuracy: 0.0846"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/ResNet50_CIFAR/CIFAR_100/wandb/run-20230522_021825-ptsv149v/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 66s 161ms/step - loss: 4.0045 - accuracy: 0.0846 - val_loss: 4.2711 - val_accuracy: 0.0648 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 2/200\n",
      "390/391 [============================>.] - ETA: 0s - loss: 3.3884 - accuracy: 0.1748"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/ResNet50_CIFAR/CIFAR_100/wandb/run-20230522_021825-ptsv149v/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 59s 152ms/step - loss: 3.3874 - accuracy: 0.1751 - val_loss: 3.5464 - val_accuracy: 0.1572 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 3/200\n",
      "390/391 [============================>.] - ETA: 0s - loss: 2.9810 - accuracy: 0.2485"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/ResNet50_CIFAR/CIFAR_100/wandb/run-20230522_021825-ptsv149v/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 59s 152ms/step - loss: 2.9810 - accuracy: 0.2485 - val_loss: 3.6954 - val_accuracy: 0.1715 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 4/200\n",
      "390/391 [============================>.] - ETA: 0s - loss: 2.7261 - accuracy: 0.2947"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/ResNet50_CIFAR/CIFAR_100/wandb/run-20230522_021825-ptsv149v/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 60s 153ms/step - loss: 2.7267 - accuracy: 0.2946 - val_loss: 3.1508 - val_accuracy: 0.2386 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 5/200\n",
      "390/391 [============================>.] - ETA: 0s - loss: 2.5271 - accuracy: 0.3350"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/ResNet50_CIFAR/CIFAR_100/wandb/run-20230522_021825-ptsv149v/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 60s 153ms/step - loss: 2.5274 - accuracy: 0.3348 - val_loss: 3.0090 - val_accuracy: 0.2554 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 6/200\n",
      "390/391 [============================>.] - ETA: 0s - loss: 2.3705 - accuracy: 0.3682"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/ResNet50_CIFAR/CIFAR_100/wandb/run-20230522_021825-ptsv149v/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 60s 155ms/step - loss: 2.3702 - accuracy: 0.3682 - val_loss: 2.5960 - val_accuracy: 0.3228 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 2.2457 - accuracy: 0.3941 - val_loss: 2.7858 - val_accuracy: 0.3058 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 2.1511 - accuracy: 0.4159 - val_loss: 2.7954 - val_accuracy: 0.3074 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 9/200\n",
      "390/391 [============================>.] - ETA: 0s - loss: 2.0635 - accuracy: 0.4360"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/ResNet50_CIFAR/CIFAR_100/wandb/run-20230522_021825-ptsv149v/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 60s 154ms/step - loss: 2.0638 - accuracy: 0.4360 - val_loss: 2.4862 - val_accuracy: 0.3569 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 10/200\n",
      "390/391 [============================>.] - ETA: 0s - loss: 1.9834 - accuracy: 0.4539"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/ResNet50_CIFAR/CIFAR_100/wandb/run-20230522_021825-ptsv149v/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 59s 152ms/step - loss: 1.9832 - accuracy: 0.4538 - val_loss: 2.4455 - val_accuracy: 0.3688 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 11/200\n",
      "390/391 [============================>.] - ETA: 0s - loss: 1.9135 - accuracy: 0.4685"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/ResNet50_CIFAR/CIFAR_100/wandb/run-20230522_021825-ptsv149v/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 60s 154ms/step - loss: 1.9135 - accuracy: 0.4684 - val_loss: 2.3948 - val_accuracy: 0.3853 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 12/200\n",
      "390/391 [============================>.] - ETA: 0s - loss: 1.8674 - accuracy: 0.4809"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/ResNet50_CIFAR/CIFAR_100/wandb/run-20230522_021825-ptsv149v/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 59s 152ms/step - loss: 1.8672 - accuracy: 0.4809 - val_loss: 2.2593 - val_accuracy: 0.4031 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 1.8015 - accuracy: 0.4970 - val_loss: 2.2688 - val_accuracy: 0.4015 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 14/200\n",
      "390/391 [============================>.] - ETA: 0s - loss: 1.7560 - accuracy: 0.5063"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/ResNet50_CIFAR/CIFAR_100/wandb/run-20230522_021825-ptsv149v/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 60s 153ms/step - loss: 1.7558 - accuracy: 0.5063 - val_loss: 2.2258 - val_accuracy: 0.4126 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 15/200\n",
      "390/391 [============================>.] - ETA: 0s - loss: 1.7034 - accuracy: 0.5193"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/ResNet50_CIFAR/CIFAR_100/wandb/run-20230522_021825-ptsv149v/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 59s 151ms/step - loss: 1.7033 - accuracy: 0.5194 - val_loss: 1.9569 - val_accuracy: 0.4652 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 1.6627 - accuracy: 0.5298 - val_loss: 2.0068 - val_accuracy: 0.4566 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 1.6286 - accuracy: 0.5382 - val_loss: 2.4785 - val_accuracy: 0.3849 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 1.5855 - accuracy: 0.5500 - val_loss: 2.2654 - val_accuracy: 0.4242 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 1.5575 - accuracy: 0.5560 - val_loss: 1.9955 - val_accuracy: 0.4578 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 1.5212 - accuracy: 0.5648 - val_loss: 2.1039 - val_accuracy: 0.4430 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 1.4874 - accuracy: 0.5739 - val_loss: 2.0708 - val_accuracy: 0.4541 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 22/200\n",
      "390/391 [============================>.] - ETA: 0s - loss: 1.4586 - accuracy: 0.5791"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/ResNet50_CIFAR/CIFAR_100/wandb/run-20230522_021825-ptsv149v/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 60s 154ms/step - loss: 1.4588 - accuracy: 0.5791 - val_loss: 1.8987 - val_accuracy: 0.4836 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 1.4283 - accuracy: 0.5915 - val_loss: 2.1329 - val_accuracy: 0.4482 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 24/200\n",
      "390/391 [============================>.] - ETA: 0s - loss: 1.4023 - accuracy: 0.5931"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/ResNet50_CIFAR/CIFAR_100/wandb/run-20230522_021825-ptsv149v/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 60s 153ms/step - loss: 1.4017 - accuracy: 0.5933 - val_loss: 1.9318 - val_accuracy: 0.4844 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 25/200\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 1.3721 - accuracy: 0.6013 - val_loss: 1.9315 - val_accuracy: 0.4782 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 26/200\n",
      "389/391 [============================>.] - ETA: 0s - loss: 1.3510 - accuracy: 0.6080"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/ResNet50_CIFAR/CIFAR_100/wandb/run-20230522_021825-ptsv149v/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 60s 153ms/step - loss: 1.3523 - accuracy: 0.6076 - val_loss: 1.9574 - val_accuracy: 0.4852 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 27/200\n",
      "390/391 [============================>.] - ETA: 0s - loss: 1.3247 - accuracy: 0.6160"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/ResNet50_CIFAR/CIFAR_100/wandb/run-20230522_021825-ptsv149v/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 60s 153ms/step - loss: 1.3252 - accuracy: 0.6159 - val_loss: 1.7821 - val_accuracy: 0.5169 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 28/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 1.3013 - accuracy: 0.6197 - val_loss: 1.8769 - val_accuracy: 0.4966 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 29/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 1.2883 - accuracy: 0.6253 - val_loss: 1.8450 - val_accuracy: 0.5118 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 30/200\n",
      "391/391 [==============================] - 49s 127ms/step - loss: 1.2606 - accuracy: 0.6298 - val_loss: 1.9246 - val_accuracy: 0.4964 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 31/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 1.2359 - accuracy: 0.6393"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/ResNet50_CIFAR/CIFAR_100/wandb/run-20230522_021825-ptsv149v/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 60s 153ms/step - loss: 1.2359 - accuracy: 0.6393 - val_loss: 1.7793 - val_accuracy: 0.5214 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 32/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 1.2259 - accuracy: 0.6392 - val_loss: 1.9391 - val_accuracy: 0.4939 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 33/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 1.2085 - accuracy: 0.6431 - val_loss: 2.0252 - val_accuracy: 0.4852 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 34/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 1.1898 - accuracy: 0.6498 - val_loss: 1.8819 - val_accuracy: 0.5054 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 35/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 1.1601 - accuracy: 0.6548 - val_loss: 1.8976 - val_accuracy: 0.5017 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 36/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 1.1526 - accuracy: 0.6583 - val_loss: 1.9182 - val_accuracy: 0.5026 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 37/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 1.1371 - accuracy: 0.6622 - val_loss: 2.0010 - val_accuracy: 0.4976 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 38/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 1.1175 - accuracy: 0.6670 - val_loss: 1.8555 - val_accuracy: 0.5176 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 39/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 1.1137 - accuracy: 0.6677 - val_loss: 1.8424 - val_accuracy: 0.5142 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 40/200\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 1.0857 - accuracy: 0.6761 - val_loss: 2.0488 - val_accuracy: 0.4831 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 41/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 1.0813 - accuracy: 0.6779 - val_loss: 1.8790 - val_accuracy: 0.5094 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 42/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 1.0625 - accuracy: 0.6809 - val_loss: 1.8891 - val_accuracy: 0.5147 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 43/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 1.0507 - accuracy: 0.6861 - val_loss: 1.8523 - val_accuracy: 0.5161 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 44/200\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 1.0309 - accuracy: 0.6889 - val_loss: 2.0159 - val_accuracy: 0.4884 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 45/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 1.0227 - accuracy: 0.6937 - val_loss: 1.9046 - val_accuracy: 0.5080 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 46/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 1.0103 - accuracy: 0.6953 - val_loss: 1.8950 - val_accuracy: 0.5113 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 47/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.9978 - accuracy: 0.6969 - val_loss: 2.0317 - val_accuracy: 0.4977 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 48/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.9774 - accuracy: 0.7045 - val_loss: 1.9652 - val_accuracy: 0.5052 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 49/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.9720 - accuracy: 0.7073 - val_loss: 1.9607 - val_accuracy: 0.5122 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 50/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.9569 - accuracy: 0.7096 - val_loss: 2.0568 - val_accuracy: 0.5051 - lr: 0.0010\n",
      "Learning rate: 0.001\n",
      "Epoch 51/200\n",
      "390/391 [============================>.] - ETA: 0s - loss: 0.9440 - accuracy: 0.7158"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/ResNet50_CIFAR/CIFAR_100/wandb/run-20230522_021825-ptsv149v/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 60s 153ms/step - loss: 0.9441 - accuracy: 0.7158 - val_loss: 1.9382 - val_accuracy: 0.5225 - lr: 0.0010\n",
      "Learning rate: 0.0001\n",
      "Epoch 52/200\n",
      "390/391 [============================>.] - ETA: 0s - loss: 0.7892 - accuracy: 0.7637"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/ResNet50_CIFAR/CIFAR_100/wandb/run-20230522_021825-ptsv149v/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 60s 153ms/step - loss: 0.7888 - accuracy: 0.7638 - val_loss: 1.5194 - val_accuracy: 0.5908 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 53/200\n",
      "390/391 [============================>.] - ETA: 0s - loss: 0.7434 - accuracy: 0.7786"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/ResNet50_CIFAR/CIFAR_100/wandb/run-20230522_021825-ptsv149v/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 60s 153ms/step - loss: 0.7435 - accuracy: 0.7786 - val_loss: 1.5183 - val_accuracy: 0.5913 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 54/200\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.7204 - accuracy: 0.7857"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/ResNet50_CIFAR/CIFAR_100/wandb/run-20230522_021825-ptsv149v/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 60s 153ms/step - loss: 0.7204 - accuracy: 0.7857 - val_loss: 1.5189 - val_accuracy: 0.5923 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 55/200\n",
      "390/391 [============================>.] - ETA: 0s - loss: 0.7114 - accuracy: 0.7881"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/ResNet50_CIFAR/CIFAR_100/wandb/run-20230522_021825-ptsv149v/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 59s 151ms/step - loss: 0.7114 - accuracy: 0.7881 - val_loss: 1.5235 - val_accuracy: 0.5933 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 56/200\n",
      "391/391 [==============================] - 49s 127ms/step - loss: 0.7004 - accuracy: 0.7910 - val_loss: 1.5302 - val_accuracy: 0.5899 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 57/200\n",
      "390/391 [============================>.] - ETA: 0s - loss: 0.6909 - accuracy: 0.7956"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 33). These functions will not be directly callable after loading.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/jupyter/IHC/gain_proj/ResNet50_CIFAR/CIFAR_100/wandb/run-20230522_021825-ptsv149v/files/model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 60s 154ms/step - loss: 0.6909 - accuracy: 0.7956 - val_loss: 1.5237 - val_accuracy: 0.5947 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 58/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.6854 - accuracy: 0.7960 - val_loss: 1.5334 - val_accuracy: 0.5937 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 59/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.6836 - accuracy: 0.7953 - val_loss: 1.5463 - val_accuracy: 0.5911 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 60/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.6734 - accuracy: 0.8005 - val_loss: 1.5556 - val_accuracy: 0.5916 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 61/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.6692 - accuracy: 0.8002 - val_loss: 1.5414 - val_accuracy: 0.5897 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 62/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.6650 - accuracy: 0.8004 - val_loss: 1.5538 - val_accuracy: 0.5892 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 63/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.6560 - accuracy: 0.8054 - val_loss: 1.5540 - val_accuracy: 0.5944 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 64/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.6541 - accuracy: 0.8038 - val_loss: 1.5632 - val_accuracy: 0.5878 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 65/200\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 0.6494 - accuracy: 0.8068 - val_loss: 1.5708 - val_accuracy: 0.5880 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 66/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.6466 - accuracy: 0.8064 - val_loss: 1.5578 - val_accuracy: 0.5921 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 67/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.6358 - accuracy: 0.8101 - val_loss: 1.5772 - val_accuracy: 0.5906 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 68/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.6339 - accuracy: 0.8096 - val_loss: 1.5782 - val_accuracy: 0.5905 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 69/200\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 0.6325 - accuracy: 0.8097 - val_loss: 1.5733 - val_accuracy: 0.5912 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 70/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.6253 - accuracy: 0.8114 - val_loss: 1.5777 - val_accuracy: 0.5919 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 71/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.6193 - accuracy: 0.8135 - val_loss: 1.5926 - val_accuracy: 0.5877 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 72/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.6208 - accuracy: 0.8146 - val_loss: 1.5942 - val_accuracy: 0.5883 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 73/200\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 0.6112 - accuracy: 0.8167 - val_loss: 1.5929 - val_accuracy: 0.5904 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 74/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.6114 - accuracy: 0.8176 - val_loss: 1.6042 - val_accuracy: 0.5869 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 75/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.6019 - accuracy: 0.8196 - val_loss: 1.6153 - val_accuracy: 0.5857 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 76/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.6052 - accuracy: 0.8182 - val_loss: 1.6058 - val_accuracy: 0.5876 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 77/200\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 0.5958 - accuracy: 0.8216 - val_loss: 1.6170 - val_accuracy: 0.5852 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 78/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.5943 - accuracy: 0.8215 - val_loss: 1.6242 - val_accuracy: 0.5894 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 79/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.5906 - accuracy: 0.8231 - val_loss: 1.6244 - val_accuracy: 0.5848 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 80/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.5908 - accuracy: 0.8208 - val_loss: 1.6355 - val_accuracy: 0.5860 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 81/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.5837 - accuracy: 0.8246 - val_loss: 1.6323 - val_accuracy: 0.5870 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 82/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.5868 - accuracy: 0.8225 - val_loss: 1.6312 - val_accuracy: 0.5831 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 83/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.5778 - accuracy: 0.8260 - val_loss: 1.6436 - val_accuracy: 0.5845 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 84/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.5741 - accuracy: 0.8273 - val_loss: 1.6491 - val_accuracy: 0.5842 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 85/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.5701 - accuracy: 0.8280 - val_loss: 1.6544 - val_accuracy: 0.5839 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 86/200\n",
      "391/391 [==============================] - 49s 127ms/step - loss: 0.5689 - accuracy: 0.8268 - val_loss: 1.6698 - val_accuracy: 0.5795 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 87/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.5684 - accuracy: 0.8279 - val_loss: 1.6547 - val_accuracy: 0.5869 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 88/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.5622 - accuracy: 0.8295 - val_loss: 1.6758 - val_accuracy: 0.5835 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 89/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.5611 - accuracy: 0.8297 - val_loss: 1.6635 - val_accuracy: 0.5850 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 90/200\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 0.5557 - accuracy: 0.8307 - val_loss: 1.6756 - val_accuracy: 0.5846 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 91/200\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 0.5550 - accuracy: 0.8316 - val_loss: 1.6725 - val_accuracy: 0.5798 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 92/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.5533 - accuracy: 0.8332 - val_loss: 1.6825 - val_accuracy: 0.5867 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 93/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.5449 - accuracy: 0.8355 - val_loss: 1.6875 - val_accuracy: 0.5814 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 94/200\n",
      "391/391 [==============================] - 49s 127ms/step - loss: 0.5430 - accuracy: 0.8346 - val_loss: 1.6913 - val_accuracy: 0.5812 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 95/200\n",
      "391/391 [==============================] - 49s 127ms/step - loss: 0.5448 - accuracy: 0.8330 - val_loss: 1.6945 - val_accuracy: 0.5841 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 96/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.5400 - accuracy: 0.8375 - val_loss: 1.6959 - val_accuracy: 0.5822 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 97/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.5347 - accuracy: 0.8377 - val_loss: 1.6947 - val_accuracy: 0.5829 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 98/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.5379 - accuracy: 0.8375 - val_loss: 1.7059 - val_accuracy: 0.5824 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 99/200\n",
      "391/391 [==============================] - 49s 127ms/step - loss: 0.5294 - accuracy: 0.8406 - val_loss: 1.7283 - val_accuracy: 0.5824 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 100/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.5262 - accuracy: 0.8411 - val_loss: 1.7166 - val_accuracy: 0.5816 - lr: 1.0000e-04\n",
      "Learning rate: 0.0001\n",
      "Epoch 101/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.5273 - accuracy: 0.8401 - val_loss: 1.7073 - val_accuracy: 0.5854 - lr: 1.0000e-04\n",
      "Learning rate: 1e-05\n",
      "Epoch 102/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.5076 - accuracy: 0.8482 - val_loss: 1.7030 - val_accuracy: 0.5874 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 103/200\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 0.5025 - accuracy: 0.8501 - val_loss: 1.7021 - val_accuracy: 0.5879 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 104/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.5029 - accuracy: 0.8506 - val_loss: 1.7026 - val_accuracy: 0.5889 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 105/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.5037 - accuracy: 0.8499 - val_loss: 1.7014 - val_accuracy: 0.5871 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 106/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4999 - accuracy: 0.8505 - val_loss: 1.7011 - val_accuracy: 0.5863 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 107/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.5001 - accuracy: 0.8506 - val_loss: 1.7021 - val_accuracy: 0.5873 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 108/200\n",
      "391/391 [==============================] - 49s 127ms/step - loss: 0.5002 - accuracy: 0.8495 - val_loss: 1.7024 - val_accuracy: 0.5869 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 109/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.4957 - accuracy: 0.8522 - val_loss: 1.7026 - val_accuracy: 0.5866 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 110/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4992 - accuracy: 0.8489 - val_loss: 1.7045 - val_accuracy: 0.5868 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 111/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.4924 - accuracy: 0.8534 - val_loss: 1.7039 - val_accuracy: 0.5864 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 112/200\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 0.4972 - accuracy: 0.8530 - val_loss: 1.7045 - val_accuracy: 0.5862 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 113/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4953 - accuracy: 0.8527 - val_loss: 1.7032 - val_accuracy: 0.5855 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 114/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4951 - accuracy: 0.8528 - val_loss: 1.7073 - val_accuracy: 0.5865 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 115/200\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 0.4934 - accuracy: 0.8530 - val_loss: 1.7073 - val_accuracy: 0.5857 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 116/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.4895 - accuracy: 0.8524 - val_loss: 1.7062 - val_accuracy: 0.5844 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 117/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.4922 - accuracy: 0.8526 - val_loss: 1.7095 - val_accuracy: 0.5851 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 118/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.4944 - accuracy: 0.8529 - val_loss: 1.7069 - val_accuracy: 0.5852 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 119/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4917 - accuracy: 0.8525 - val_loss: 1.7103 - val_accuracy: 0.5849 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 120/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4895 - accuracy: 0.8542 - val_loss: 1.7092 - val_accuracy: 0.5852 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 121/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4878 - accuracy: 0.8566 - val_loss: 1.7087 - val_accuracy: 0.5857 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 122/200\n",
      "391/391 [==============================] - 50s 129ms/step - loss: 0.4931 - accuracy: 0.8544 - val_loss: 1.7127 - val_accuracy: 0.5853 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 123/200\n",
      "391/391 [==============================] - 50s 129ms/step - loss: 0.4911 - accuracy: 0.8548 - val_loss: 1.7119 - val_accuracy: 0.5840 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 124/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.4910 - accuracy: 0.8532 - val_loss: 1.7130 - val_accuracy: 0.5844 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 125/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.4900 - accuracy: 0.8549 - val_loss: 1.7145 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 126/200\n",
      "391/391 [==============================] - 50s 129ms/step - loss: 0.4911 - accuracy: 0.8532 - val_loss: 1.7158 - val_accuracy: 0.5840 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 127/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4871 - accuracy: 0.8554 - val_loss: 1.7121 - val_accuracy: 0.5854 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 128/200\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 0.4849 - accuracy: 0.8556 - val_loss: 1.7136 - val_accuracy: 0.5855 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 129/200\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 0.4890 - accuracy: 0.8529 - val_loss: 1.7160 - val_accuracy: 0.5850 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 130/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4897 - accuracy: 0.8527 - val_loss: 1.7172 - val_accuracy: 0.5847 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 131/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4914 - accuracy: 0.8541 - val_loss: 1.7176 - val_accuracy: 0.5845 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 132/200\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 0.4882 - accuracy: 0.8545 - val_loss: 1.7169 - val_accuracy: 0.5851 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 133/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4882 - accuracy: 0.8549 - val_loss: 1.7165 - val_accuracy: 0.5851 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 134/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4834 - accuracy: 0.8560 - val_loss: 1.7199 - val_accuracy: 0.5846 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 135/200\n",
      "391/391 [==============================] - 50s 129ms/step - loss: 0.4866 - accuracy: 0.8538 - val_loss: 1.7185 - val_accuracy: 0.5865 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 136/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.4880 - accuracy: 0.8537 - val_loss: 1.7181 - val_accuracy: 0.5859 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 137/200\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 0.4884 - accuracy: 0.8545 - val_loss: 1.7201 - val_accuracy: 0.5846 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 138/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4880 - accuracy: 0.8539 - val_loss: 1.7207 - val_accuracy: 0.5860 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 139/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4897 - accuracy: 0.8546 - val_loss: 1.7202 - val_accuracy: 0.5844 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 140/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4875 - accuracy: 0.8530 - val_loss: 1.7210 - val_accuracy: 0.5840 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 141/200\n",
      "391/391 [==============================] - 49s 127ms/step - loss: 0.4846 - accuracy: 0.8555 - val_loss: 1.7253 - val_accuracy: 0.5847 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 142/200\n",
      "391/391 [==============================] - 50s 129ms/step - loss: 0.4816 - accuracy: 0.8578 - val_loss: 1.7207 - val_accuracy: 0.5840 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 143/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4818 - accuracy: 0.8549 - val_loss: 1.7232 - val_accuracy: 0.5852 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 144/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4830 - accuracy: 0.8561 - val_loss: 1.7241 - val_accuracy: 0.5857 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 145/200\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 0.4826 - accuracy: 0.8555 - val_loss: 1.7259 - val_accuracy: 0.5858 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 146/200\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 0.4865 - accuracy: 0.8557 - val_loss: 1.7275 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 147/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4815 - accuracy: 0.8552 - val_loss: 1.7270 - val_accuracy: 0.5831 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 148/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4796 - accuracy: 0.8561 - val_loss: 1.7282 - val_accuracy: 0.5855 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 149/200\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 0.4866 - accuracy: 0.8564 - val_loss: 1.7259 - val_accuracy: 0.5842 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 150/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.4839 - accuracy: 0.8548 - val_loss: 1.7272 - val_accuracy: 0.5854 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 151/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4798 - accuracy: 0.8562 - val_loss: 1.7286 - val_accuracy: 0.5837 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 152/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4810 - accuracy: 0.8555 - val_loss: 1.7285 - val_accuracy: 0.5852 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 153/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.4759 - accuracy: 0.8572 - val_loss: 1.7294 - val_accuracy: 0.5848 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 154/200\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 0.4721 - accuracy: 0.8580 - val_loss: 1.7290 - val_accuracy: 0.5845 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 155/200\n",
      "391/391 [==============================] - 50s 129ms/step - loss: 0.4823 - accuracy: 0.8567 - val_loss: 1.7305 - val_accuracy: 0.5856 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 156/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4783 - accuracy: 0.8580 - val_loss: 1.7312 - val_accuracy: 0.5854 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 157/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.4802 - accuracy: 0.8575 - val_loss: 1.7303 - val_accuracy: 0.5867 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 158/200\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 0.4799 - accuracy: 0.8563 - val_loss: 1.7334 - val_accuracy: 0.5847 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 159/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.4781 - accuracy: 0.8570 - val_loss: 1.7346 - val_accuracy: 0.5846 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 160/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4789 - accuracy: 0.8587 - val_loss: 1.7330 - val_accuracy: 0.5847 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 161/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.4767 - accuracy: 0.8565 - val_loss: 1.7345 - val_accuracy: 0.5850 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 162/200\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 0.4761 - accuracy: 0.8575 - val_loss: 1.7348 - val_accuracy: 0.5849 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 163/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4772 - accuracy: 0.8573 - val_loss: 1.7341 - val_accuracy: 0.5851 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 164/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4777 - accuracy: 0.8564 - val_loss: 1.7360 - val_accuracy: 0.5850 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 165/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.4778 - accuracy: 0.8578 - val_loss: 1.7355 - val_accuracy: 0.5845 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 166/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.4797 - accuracy: 0.8575 - val_loss: 1.7354 - val_accuracy: 0.5844 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 167/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.4756 - accuracy: 0.8574 - val_loss: 1.7371 - val_accuracy: 0.5839 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 168/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.4793 - accuracy: 0.8572 - val_loss: 1.7384 - val_accuracy: 0.5839 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 169/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4720 - accuracy: 0.8612 - val_loss: 1.7393 - val_accuracy: 0.5845 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 170/200\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 0.4738 - accuracy: 0.8560 - val_loss: 1.7405 - val_accuracy: 0.5845 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 171/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.4768 - accuracy: 0.8568 - val_loss: 1.7412 - val_accuracy: 0.5833 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 172/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4779 - accuracy: 0.8576 - val_loss: 1.7398 - val_accuracy: 0.5846 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 173/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4735 - accuracy: 0.8583 - val_loss: 1.7400 - val_accuracy: 0.5836 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 174/200\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 0.4738 - accuracy: 0.8566 - val_loss: 1.7405 - val_accuracy: 0.5844 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 175/200\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 0.4756 - accuracy: 0.8577 - val_loss: 1.7415 - val_accuracy: 0.5833 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 176/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4716 - accuracy: 0.8595 - val_loss: 1.7434 - val_accuracy: 0.5844 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 177/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4740 - accuracy: 0.8582 - val_loss: 1.7448 - val_accuracy: 0.5823 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 178/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.4699 - accuracy: 0.8597 - val_loss: 1.7453 - val_accuracy: 0.5841 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 179/200\n",
      "391/391 [==============================] - 49s 125ms/step - loss: 0.4740 - accuracy: 0.8591 - val_loss: 1.7460 - val_accuracy: 0.5840 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 180/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4753 - accuracy: 0.8576 - val_loss: 1.7450 - val_accuracy: 0.5819 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 181/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4723 - accuracy: 0.8597 - val_loss: 1.7465 - val_accuracy: 0.5822 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 182/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4681 - accuracy: 0.8603 - val_loss: 1.7474 - val_accuracy: 0.5840 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 183/200\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 0.4687 - accuracy: 0.8595 - val_loss: 1.7466 - val_accuracy: 0.5829 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 184/200\n",
      "391/391 [==============================] - 49s 127ms/step - loss: 0.4713 - accuracy: 0.8596 - val_loss: 1.7479 - val_accuracy: 0.5840 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 185/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.4684 - accuracy: 0.8595 - val_loss: 1.7474 - val_accuracy: 0.5849 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 186/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.4658 - accuracy: 0.8608 - val_loss: 1.7464 - val_accuracy: 0.5839 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 187/200\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 0.4716 - accuracy: 0.8592 - val_loss: 1.7474 - val_accuracy: 0.5843 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 188/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.4625 - accuracy: 0.8619 - val_loss: 1.7480 - val_accuracy: 0.5849 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 191/200\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 0.4691 - accuracy: 0.8600 - val_loss: 1.7512 - val_accuracy: 0.5838 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 192/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.4677 - accuracy: 0.8580 - val_loss: 1.7502 - val_accuracy: 0.5849 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 193/200\n",
      "391/391 [==============================] - 50s 129ms/step - loss: 0.4695 - accuracy: 0.8606 - val_loss: 1.7505 - val_accuracy: 0.5844 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 194/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4612 - accuracy: 0.8629 - val_loss: 1.7526 - val_accuracy: 0.5845 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 195/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.4684 - accuracy: 0.8601 - val_loss: 1.7529 - val_accuracy: 0.5833 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 196/200\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 0.4664 - accuracy: 0.8601 - val_loss: 1.7537 - val_accuracy: 0.5824 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 197/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.4685 - accuracy: 0.8598 - val_loss: 1.7541 - val_accuracy: 0.5823 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 198/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4659 - accuracy: 0.8590 - val_loss: 1.7533 - val_accuracy: 0.5838 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 199/200\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.4611 - accuracy: 0.8641 - val_loss: 1.7546 - val_accuracy: 0.5847 - lr: 1.0000e-05\n",
      "Learning rate: 1e-05\n",
      "Epoch 200/200\n",
      "391/391 [==============================] - 50s 127ms/step - loss: 0.4643 - accuracy: 0.8608 - val_loss: 1.7540 - val_accuracy: 0.5840 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fac24c9de20>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(datagen.flow(x_train, y_train, batch_size=128),\n",
    "          validation_data=(x_test, y_test),\n",
    "          epochs=200, workers=4,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b680e-40d0-4d11-9d99-3e44c26ad381",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
